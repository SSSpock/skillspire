{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNuv4B2z2OkRSzIIXIxfHaw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SSSpock/skillspire/blob/main/casestudy_2ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m34sOgXOJDG1",
        "outputId": "089e0c83-e107-4ab5-ace0-a2675f71918a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting faker\n",
            "  Downloading Faker-18.4.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.9/dist-packages (from faker) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.4->faker) (1.16.0)\n",
            "Installing collected packages: faker\n",
            "Successfully installed faker-18.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Users DF\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from faker import Faker\n",
        "\n",
        "# Initialize the Faker library\n",
        "fake = Faker()\n",
        "\n",
        "# Define the number of unique users\n",
        "num_users = 100000\n",
        "\n",
        "# Generate user_id\n",
        "user_id = list(range(1, num_users + 1))\n",
        "\n",
        "# Generate age\n",
        "median_age = 25\n",
        "ages = np.random.normal(loc=median_age, scale=5, size=num_users).astype(int)\n",
        "\n",
        "# Generate gender\n",
        "gender_ratio = [0.48, 0.5, 0.01, 0.01]  # Male, Female, Non-Binary, Prefer not to say\n",
        "gender = np.random.choice([\"Male\", \"Female\", \"Non-Binary\", \"Prefer not to say\"], size=num_users, p=gender_ratio)\n",
        "\n",
        "# Generate country\n",
        "countries = [\"United States\", \"United Kingdom\", \"France\", \"Germany\", \"Spain\", \"Italy\", \"Netherlands\", \"Belgium\", \"Sweden\", \"Norway\", \"Denmark\", \"Finland\", \"Switzerland\", \"Ireland\", \"Austria\", \"Portugal\", \"Greece\"]\n",
        "country = np.random.choice(countries, size=num_users)\n",
        "\n",
        "# Generate signup_date\n",
        "signup_dates = [fake.date_between(start_date='-3y', end_date='today') for _ in range(num_users)]\n",
        "\n",
        "# Generate subscription_type\n",
        "subscription_ratio = [0.6, 0.3, 0.1]  # Free, Basic, Premium\n",
        "subscription_type = np.random.choice([\"Free\", \"Basic\", \"Premium\"], size=num_users, p=subscription_ratio)\n",
        "\n",
        "# Create the Users DataFrame\n",
        "users_df = pd.DataFrame({\"user_id\": user_id, \"age\": ages, \"gender\": gender, \"country\": country, \"signup_date\": signup_dates, \"subscription_type\": subscription_type})\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "users_df.to_csv(\"user_data.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "BCzSUmNYIy6A"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Content df\n",
        "\n",
        "# Define the number of content items\n",
        "num_content = 5000\n",
        "\n",
        "# Generate content_id\n",
        "content_id = list(range(1, num_content + 1))\n",
        "\n",
        "# Generate content_type\n",
        "content_type_ratio = [0.6, 0.35, 0.05]  # Movie, TV Show, Live Event\n",
        "content_type = np.random.choice([\"Movie\", \"TV Show\", \"Live Event\"], size=num_content, p=content_type_ratio)\n",
        "\n",
        "# Generate genre\n",
        "genres = [\"Action\", \"Comedy\", \"Drama\", \"Documentary\", \"Thriller\", \"Horror\", \"Sci-Fi\", \"Romance\", \"Animation\", \"Crime\", \"Family\", \"Adventure\", \"Fantasy\", \"Mystery\", \"Biography\", \"History\", \"Sport\", \"Music\", \"War\", \"Western\"]\n",
        "genre = np.random.choice(genres, size=num_content)\n",
        "\n",
        "# Generate release_year\n",
        "release_years = np.random.randint(low=1990, high=2023, size=num_content)\n",
        "\n",
        "# Generate duration_minutes\n",
        "duration_minutes = np.random.randint(low=30, high=240, size=num_content)\n",
        "\n",
        "# Generate average_user_rating\n",
        "average_user_rating = np.random.uniform(low=1, high=5, size=num_content).round(1)\n",
        "\n",
        "# Create the Content DataFrame\n",
        "content_df = pd.DataFrame({\"content_id\": content_id, \"content_type\": content_type, \"genre\": genre, \"release_year\": release_years, \"duration_minutes\": duration_minutes, \"average_user_rating\": average_user_rating})\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "content_df.to_csv(\"content_data.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "-V8W7dPeMmDs"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# User-content Interactions\n",
        "\n",
        "# Define the number of interactions\n",
        "num_interactions = 50000\n",
        "\n",
        "# Generate user_id for interactions\n",
        "interaction_user_id = np.random.choice(user_id, size=num_interactions)\n",
        "\n",
        "# Generate content_id for interactions\n",
        "interaction_content_id = np.random.choice(content_id, size=num_interactions)\n",
        "\n",
        "# Create a temporary Interactions DataFrame\n",
        "temp_interactions_df = pd.DataFrame({\"user_id\": interaction_user_id, \"content_id\": interaction_content_id})\n",
        "\n",
        "# Merge the Users DataFrame with the temporary Interactions DataFrame on user_id\n",
        "merged_df = temp_interactions_df.merge(users_df[[\"user_id\", \"signup_date\"]], on=\"user_id\")\n",
        "\n",
        "# Generate interaction_timestamp ensuring it's after the user's signup_date\n",
        "merged_df[\"interaction_timestamp\"] = merged_df[\"signup_date\"].apply(lambda x: fake.date_time_between(start_date=x, end_date='now', tzinfo=None))\n",
        "\n",
        "# Generate interaction_type\n",
        "interaction_types = [\"Played\", \"Liked\", \"Disliked\", \"Added to Playlist\", \"Shared\"]\n",
        "interaction_type = np.random.choice(interaction_types, size=num_interactions)\n",
        "\n",
        "# Add interaction_type to the merged DataFrame\n",
        "merged_df[\"interaction_type\"] = interaction_type\n",
        "\n",
        "# Create the final User-Content Interactions DataFrame\n",
        "interactions_df = merged_df[[\"user_id\", \"content_id\", \"interaction_type\", \"interaction_timestamp\"]]\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "interactions_df.to_csv(\"interactions_data.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "6zNtp2vxMo2G"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Revenue DF\n",
        "\n",
        "# Sample a subset of interactions as revenue-generating events\n",
        "revenue_interactions_df = interactions_df.sample(frac=0.4, random_state=42)\n",
        "\n",
        "# Generate revenue_amount using a log-normal distribution\n",
        "mu, sigma = 0, 1\n",
        "revenue_amount = np.random.lognormal(mean=mu, sigma=sigma, size=len(revenue_interactions_df))\n",
        "revenue_amount = np.round(revenue_amount * 10, 2)  # Scale and round the values\n",
        "\n",
        "# Add revenue_amount to the revenue_interactions_df\n",
        "revenue_interactions_df[\"revenue_amount\"] = revenue_amount\n",
        "\n",
        "# Generate revenue_type based on content_type\n",
        "content_type_revenue_ratio = {\n",
        "    \"Movie\": [0.3, 0.6, 0.1],\n",
        "    \"TV Show\": [0.4, 0.5, 0.1],\n",
        "    \"Live Event\": [0.2, 0.3, 0.5]\n",
        "}\n",
        "\n",
        "def generate_revenue_type(row):\n",
        "    content_type = content_df.loc[content_df[\"content_id\"] == row[\"content_id\"], \"content_type\"].values[0]\n",
        "    return np.random.choice([\"Subscription\", \"Advertisement\", \"In-app Purchase\"], p=content_type_revenue_ratio[content_type])\n",
        "\n",
        "revenue_interactions_df[\"revenue_type\"] = revenue_interactions_df.apply(generate_revenue_type, axis=1)\n",
        "\n",
        "# Generate transaction_date based on interaction_timestamp\n",
        "revenue_interactions_df[\"transaction_date\"] = revenue_interactions_df[\"interaction_timestamp\"].dt.date\n",
        "\n",
        "# Create the Revenue DataFrame\n",
        "revenue_df = revenue_interactions_df[[\"user_id\", \"content_id\", \"revenue_amount\", \"revenue_type\", \"transaction_date\"]]\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "revenue_df.to_csv(\"revenue_data.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "26qdEof8N3RF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of A/B test interactions\n",
        "num_ab_test_interactions = 10000\n",
        "\n",
        "# Generate user_id for A/B test interactions\n",
        "ab_test_user_id = np.random.choice(user_id, size=num_ab_test_interactions)\n",
        "\n",
        "# Generate content_id for A/B test interactions\n",
        "ab_test_content_id = np.random.choice(content_id, size=num_ab_test_interactions)\n",
        "\n",
        "# Generate group (Control or Test)\n",
        "group = np.random.choice([\"Control\", \"Test\"], size=num_ab_test_interactions)\n",
        "\n",
        "# Create a temporary A/B Test Interactions DataFrame\n",
        "temp_ab_test_interactions_df = pd.DataFrame({\"user_id\": ab_test_user_id, \"content_id\": ab_test_content_id, \"group\": group})\n",
        "\n",
        "# Merge the Users DataFrame with the temporary A/B Test Interactions DataFrame on user_id\n",
        "merged_ab_test_df = temp_ab_test_interactions_df.merge(users_df[[\"user_id\", \"signup_date\"]], on=\"user_id\")\n",
        "\n",
        "# Generate interaction_timestamp ensuring it's after the user's signup_date\n",
        "merged_ab_test_df[\"interaction_timestamp\"] = merged_ab_test_df[\"signup_date\"].apply(lambda x: fake.date_time_between(start_date=x, end_date='now', tzinfo=None))\n",
        "\n",
        "# Generate interaction_type\n",
        "ab_test_interaction_types = [\"Played\", \"Liked\", \"Disliked\"]\n",
        "ab_test_interaction_type = np.random.choice(ab_test_interaction_types, size=num_ab_test_interactions)\n",
        "\n",
        "# Add interaction_type to the merged A/B Test DataFrame\n",
        "merged_ab_test_df[\"interaction_type\"] = ab_test_interaction_type\n",
        "\n",
        "# Create the final A/B Test Interactions DataFrame\n",
        "ab_test_interactions_df = merged_ab_test_df[[\"user_id\", \"content_id\", \"group\", \"interaction_type\", \"interaction_timestamp\"]]\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "ab_test_interactions_df.to_csv(\"ab_test_data.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "QAWCPTwuT_Wk"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Case Study: Tech Startup \"StreamVision\"\n",
        "\n",
        "# Backstory:\n",
        "\n",
        "StreamVision is a technology startup that has recently developed a cutting-edge streaming platform for movies, TV shows, and live events. The company is growing rapidly and has acquired a substantial user base in a short period. The management team is interested in using data-driven decision-making to optimize the platform's user experience and maximize revenue.\n",
        "\n",
        "As a data scientist at StreamVision, you have been tasked with analyzing the platform's usage data to identify opportunities for improvement and make data-backed recommendations to the management team.\n",
        "\n",
        "## Student Tasks:\n",
        "\n",
        "##Data Wrangling and Analysis (Week 4)\n",
        "\n",
        "Use Python and Pandas to clean and preprocess the raw usage data.\n",
        "Perform exploratory data analysis to identify trends and patterns in user behavior.\n",
        "\n",
        "## Statistical Analysis (Week 5)\n",
        "\n",
        "Apply descriptive statistics to summarize the key features of the usage data.\n",
        "Conduct hypothesis testing to validate assumptions and answer key questions posed by the management team.\n",
        "\n",
        "## Experimental Design (Week 6)\n",
        "\n",
        "Design an A/B test to evaluate the impact of potential changes to the platform (e.g., new recommendation algorithms or user interface adjustments).\n",
        "Analyze the results of the A/B test and determine if the changes had a statistically significant impact on user engagement or revenue.\n",
        "\n",
        "## Data Visualization (Week 7)\n",
        "\n",
        "Use Matplotlib and Seaborn to create visualizations that effectively communicate the findings from the data analysis.\n",
        "Present the visualizations in a way that is easily understood by the management team.\n",
        "\n",
        "## Regression Analysis (Week 8)\n",
        "\n",
        "Build and evaluate linear regression models to predict user engagement and revenue based on different platform features.\n",
        "Use model selection and regularization techniques to improve the performance of the regression models.\n",
        "Questions from Executives:\n",
        "\n",
        "What are the main factors driving user engagement and revenue on the platform?\n",
        "Are there any specific user segments or content categories that are underperforming or overperforming compared to the rest?\n",
        "Can we optimize the recommendation algorithm to increase user engagement and revenue? What changes would you propose?\n",
        "Are there any statistically significant differences in user behavior based on demographic factors or user preferences?\n",
        "How effective are the proposed platform changes based on the A/B test results? Should we implement the changes for all users?"
      ],
      "metadata": {
        "id": "BFANJvnyGQhE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Users Table (user_data.csv):\n",
        "\n",
        "user_id (integer): Unique identifier for each user.\n",
        "age (integer): Age of the user.\n",
        "gender (string): Gender of the user (Male, Female, Non-Binary, Prefer not to say).\n",
        "country (string): Country of residence of the user.\n",
        "signup_date (date): Date when the user signed up for the platform.\n",
        "subscription_type (string): Type of subscription (Free, Basic, Premium).\n",
        "\n",
        "## Content Table (content_data.csv):\n",
        "\n",
        "content_id (integer): Unique identifier for each content item.\n",
        "content_type (string): Type of content (Movie, TV Show, Live Event).\n",
        "genre (string): Genre of the content (e.g., Action, Comedy, Drama, Documentary, etc.).\n",
        "release_year (integer): Year when the content was released.\n",
        "duration_minutes (integer): Duration of the content in minutes (only applicable for Movies and TV Shows).\n",
        "average_user_rating (float): Average rating given by users for the content, ranging from 1 (lowest) to 5 (highest).\n",
        "\n",
        "## User-Content Interactions Table (interactions_data.csv):\n",
        "\n",
        "user_id (integer): Unique identifier for the user who interacted with the content.\n",
        "content_id (integer): Unique identifier for the content that was interacted with.\n",
        "interaction_type (string): Type of interaction (Played, Liked, Disliked, Added to Playlist, Shared).\n",
        "interaction_timestamp (datetime): Timestamp when the interaction occurred.\n",
        "\n",
        "## Revenue Table (revenue_data.csv):\n",
        "\n",
        "user_id (integer): Unique identifier for the user who generated the revenue.\n",
        "content_id (integer): Unique identifier for the content that generated the revenue.\n",
        "revenue_amount (float): Amount of revenue generated (in USD).\n",
        "revenue_type (string): Type of revenue (Subscription, Advertisement, In-app Purchase).\n",
        "transaction_date (date): Date when the revenue was generated.\n"
      ],
      "metadata": {
        "id": "KlwisTXcG5l4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfJYv3_JGNsy"
      },
      "outputs": [],
      "source": [
        "users_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "revenue_df"
      ],
      "metadata": {
        "id": "taDmecweSmyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interactions_df"
      ],
      "metadata": {
        "id": "9lJqavWMSydH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "content_df"
      ],
      "metadata": {
        "id": "0oq_0X_OS2EG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ab_test_interactions_df"
      ],
      "metadata": {
        "id": "rjqonGgSUCYA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}